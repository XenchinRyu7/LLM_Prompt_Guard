{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8760c8003fd2188",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Loading models from disk\n",
    "\n",
    "In this notebook, we will load the models from disk instead of pulling from HuggingFace. This is helpful when you want to deploy LLM Guard on a server and share the models with other instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6f396e2630979d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Pull models from HuggingFace\n",
    "\n",
    "First, we will pull the models from [HuggingFace and save them to disk](https://huggingface.co/docs/hub/en/models-downloading). You can also pull them from other sources and save them to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd2ad9432d5d1cd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!git lfs install\n",
    "!git clone git@hf.co:protectai/deberta-v3-base-prompt-injection-v2\n",
    "!git clone git@hf.co:MoritzLaurer/deberta-v3-base-zeroshot-v1.1-all-33\n",
    "!git clone git@hf.co:tomaarsen/span-marker-bert-base-orgs\n",
    "!git clone git@hf.co:unitary/unbiased-toxic-roberta\n",
    "!git clone git@hf.co:philomath-1209/programming-language-identification\n",
    "!git clone git@hf.co:madhurjindal/autonlp-Gibberish-Detector-492513457\n",
    "!git clone git@hf.co:papluca/xlm-roberta-base-language-detection\n",
    "!git clone git@hf.co:Isotonic/deberta-v3-base_finetuned_ai4privacy_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d3c29874857f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Note**: If you use only `ONNX` models, you can remove the other versions of the models to save disk space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1032ae1e578d87a9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Use local models in LLM Guard\n",
    "\n",
    "Now, we will use the local models in LLM Guard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5225102a4ad1007",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install llm_guard@git+https://github.com/protectai/llm-guard.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bdbb7744e414c5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:40:06.469775Z",
     "start_time": "2024-03-21T11:39:44.361526Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-03-21 12:39:44\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mNo entity types provided, using default\u001b[0m \u001b[36mdefault_entities\u001b[0m=\u001b[35m['CREDIT_CARD', 'CRYPTO', 'EMAIL_ADDRESS', 'IBAN_CODE', 'IP_ADDRESS', 'PERSON', 'PHONE_NUMBER', 'US_SSN', 'US_BANK_NUMBER', 'CREDIT_CARD_RE', 'UUID', 'EMAIL_ADDRESS_RE', 'US_SSN_RE']\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:46\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mInitialized NER model         \u001b[0m \u001b[36mdevice\u001b[0m=\u001b[35mdevice(type='mps')\u001b[0m \u001b[36mmodel\u001b[0m=\u001b[35mModel(path='./deberta-v3-base_finetuned_ai4privacy_v2', subfolder='', onnx_path='Isotonic/deberta-v3-base_finetuned_ai4privacy_v2', onnx_subfolder='onnx', onnx_filename='model.onnx', kwargs={'local_files_only': True}, pipeline_kwargs={'aggregation_strategy': 'simple', 'ignore_labels': ['O', 'CARDINAL']})\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:47\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mCREDIT_CARD_RE\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:47\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mUUID\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:47\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mEMAIL_ADDRESS_RE\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:47\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mUS_SSN_RE\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:47\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mBTC_ADDRESS\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:47\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mURL_RE\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:47\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mCREDIT_CARD\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:47\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mEMAIL_ADDRESS_RE\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:47\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mPHONE_NUMBER_ZH\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:47\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mPHONE_NUMBER_WITH_EXT\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:47\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mDATE_RE\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:47\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mTIME_RE\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:47\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mHEX_COLOR\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:47\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mPRICE_RE\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:47\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mPO_BOX_RE\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:48\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mInitialized classification model\u001b[0m \u001b[36mdevice\u001b[0m=\u001b[35mdevice(type='mps')\u001b[0m \u001b[36mmodel\u001b[0m=\u001b[35mModel(path='./deberta-v3-base-zeroshot-v1.1-all-33', subfolder='', onnx_path='MoritzLaurer/deberta-v3-base-zeroshot-v1.1-all-33', onnx_subfolder='onnx', onnx_filename='model.onnx', kwargs={'local_files_only': True, 'max_length': 1000000000000000019884624838656}, pipeline_kwargs={'max_length': 512, 'truncation': True})\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:55\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mInitialized classification model\u001b[0m \u001b[36mdevice\u001b[0m=\u001b[35mdevice(type='mps')\u001b[0m \u001b[36mmodel\u001b[0m=\u001b[35mModel(path='./unbiased-toxic-roberta', subfolder='', onnx_path='ProtectAI/unbiased-toxic-roberta-onnx', onnx_subfolder='', onnx_filename='model.onnx', kwargs={'local_files_only': True, 'max_length': 512}, pipeline_kwargs={'padding': 'max_length', 'top_k': None, 'function_to_apply': 'sigmoid', 'truncation': True})\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mInitialized classification model\u001b[0m \u001b[36mdevice\u001b[0m=\u001b[35mdevice(type='mps')\u001b[0m \u001b[36mmodel\u001b[0m=\u001b[35mModel(path='./programming-language-identification', subfolder='', onnx_path='philomath-1209/programming-language-identification-onnx', onnx_subfolder='onnx', onnx_filename='model.onnx', kwargs={'local_files_only': True, 'max_length': 512}, pipeline_kwargs={'truncation': True})\u001b[0m\n",
      "\u001b[2m2024-03-21 12:39:57\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mInitialized classification model\u001b[0m \u001b[36mdevice\u001b[0m=\u001b[35mdevice(type='mps')\u001b[0m \u001b[36mmodel\u001b[0m=\u001b[35mModel(path='./autonlp-Gibberish-Detector-492513457', subfolder='', onnx_path='madhurjindal/autonlp-Gibberish-Detector-492513457', onnx_subfolder='onnx', onnx_filename='model.onnx', kwargs={'local_files_only': True, 'max_length': 512}, pipeline_kwargs={'truncation': True})\u001b[0m\n",
      "\u001b[2m2024-03-21 12:40:01\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mInitialized classification model\u001b[0m \u001b[36mdevice\u001b[0m=\u001b[35mdevice(type='mps')\u001b[0m \u001b[36mmodel\u001b[0m=\u001b[35mModel(path='./xlm-roberta-base-language-detection', subfolder='', onnx_path='ProtectAI/xlm-roberta-base-language-detection-onnx', onnx_subfolder='', onnx_filename='model.onnx', kwargs={'local_files_only': True, 'max_length': 512}, pipeline_kwargs={'max_length': 512, 'truncation': True, 'top_k': None})\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-03-21 12:40:04\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mPrompt does not have sensitive data to replace\u001b[0m \u001b[36mrisk_score\u001b[0m=\u001b[35m0.0\u001b[0m\n",
      "\u001b[2m2024-03-21 12:40:04\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mScanner completed             \u001b[0m \u001b[36melapsed_time_seconds\u001b[0m=\u001b[35m1.366613\u001b[0m \u001b[36mis_valid\u001b[0m=\u001b[35mTrue\u001b[0m \u001b[36mscanner\u001b[0m=\u001b[35mAnonymize\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-03-21 12:40:05\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mNo banned topics detected     \u001b[0m \u001b[36mscores\u001b[0m=\u001b[35m{'religion': 0.5899404287338257, 'politics': 0.4100596308708191}\u001b[0m\n",
      "\u001b[2m2024-03-21 12:40:05\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mScanner completed             \u001b[0m \u001b[36melapsed_time_seconds\u001b[0m=\u001b[35m0.911\u001b[0m \u001b[36mis_valid\u001b[0m=\u001b[35mTrue\u001b[0m \u001b[36mscanner\u001b[0m=\u001b[35mBanTopics\u001b[0m\n",
      "\u001b[2m2024-03-21 12:40:05\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mNone of the competitors were detected\u001b[0m\n",
      "\u001b[2m2024-03-21 12:40:05\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mScanner completed             \u001b[0m \u001b[36melapsed_time_seconds\u001b[0m=\u001b[35m0.569812\u001b[0m \u001b[36mis_valid\u001b[0m=\u001b[35mTrue\u001b[0m \u001b[36mscanner\u001b[0m=\u001b[35mBanCompetitors\u001b[0m\n",
      "\u001b[2m2024-03-21 12:40:06\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mNot toxicity found in the text\u001b[0m \u001b[36mresults\u001b[0m=\u001b[35m[[{'label': 'toxicity', 'score': 0.0003712967736646533}, {'label': 'male', 'score': 0.00016587311984039843}, {'label': 'female', 'score': 0.00012892877566628158}, {'label': 'insult', 'score': 0.00011079442629124969}, {'label': 'christian', 'score': 0.0001087861746782437}, {'label': 'psychiatric_or_mental_illness', 'score': 9.981756011256948e-05}, {'label': 'muslim', 'score': 7.031546556390822e-05}, {'label': 'white', 'score': 4.716941839433275e-05}, {'label': 'jewish', 'score': 3.9232210838235915e-05}, {'label': 'identity_attack', 'score': 2.9348657335503958e-05}, {'label': 'homosexual_gay_or_lesbian', 'score': 2.922919338743668e-05}, {'label': 'threat', 'score': 2.9109109163982794e-05}, {'label': 'black', 'score': 2.897163540183101e-05}, {'label': 'obscene', 'score': 2.86914873868227e-05}, {'label': 'sexual_explicit', 'score': 1.7762333300197497e-05}, {'label': 'severe_toxicity', 'score': 1.1558224741747836e-06}]]\u001b[0m\n",
      "\u001b[2m2024-03-21 12:40:06\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mScanner completed             \u001b[0m \u001b[36melapsed_time_seconds\u001b[0m=\u001b[35m0.392971\u001b[0m \u001b[36mis_valid\u001b[0m=\u001b[35mTrue\u001b[0m \u001b[36mscanner\u001b[0m=\u001b[35mToxicity\u001b[0m\n",
      "\u001b[2m2024-03-21 12:40:06\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mNo Markdown code blocks found in the output\u001b[0m\n",
      "\u001b[2m2024-03-21 12:40:06\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mScanner completed             \u001b[0m \u001b[36melapsed_time_seconds\u001b[0m=\u001b[35m0.000252\u001b[0m \u001b[36mis_valid\u001b[0m=\u001b[35mTrue\u001b[0m \u001b[36mscanner\u001b[0m=\u001b[35mCode\u001b[0m\n",
      "\u001b[2m2024-03-21 12:40:06\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mGibberish detection finished  \u001b[0m \u001b[36mresults\u001b[0m=\u001b[35m[{'label': 'clean', 'score': 0.4235343933105469}]\u001b[0m\n",
      "\u001b[2m2024-03-21 12:40:06\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mNo gibberish in the text      \u001b[0m \u001b[36mhighest_score\u001b[0m=\u001b[35m0.58\u001b[0m \u001b[36mthreshold\u001b[0m=\u001b[35m0.7\u001b[0m\n",
      "\u001b[2m2024-03-21 12:40:06\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mScanner completed             \u001b[0m \u001b[36melapsed_time_seconds\u001b[0m=\u001b[35m0.104569\u001b[0m \u001b[36mis_valid\u001b[0m=\u001b[35mTrue\u001b[0m \u001b[36mscanner\u001b[0m=\u001b[35mGibberish\u001b[0m\n",
      "\u001b[2m2024-03-21 12:40:06\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mOnly valid languages are found in the text.\u001b[0m\n",
      "\u001b[2m2024-03-21 12:40:06\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mScanner completed             \u001b[0m \u001b[36melapsed_time_seconds\u001b[0m=\u001b[35m0.177882\u001b[0m \u001b[36mis_valid\u001b[0m=\u001b[35mTrue\u001b[0m \u001b[36mscanner\u001b[0m=\u001b[35mLanguage\u001b[0m\n",
      "\u001b[2m2024-03-21 12:40:06\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mScanned prompt                \u001b[0m \u001b[36melapsed_time_seconds\u001b[0m=\u001b[35m3.525234\u001b[0m \u001b[36mscores\u001b[0m=\u001b[35m{'Anonymize': 0.0, 'BanTopics': 0.0, 'BanCompetitors': 0.0, 'Toxicity': 0.0, 'Code': 0.0, 'Gibberish': 0.0, 'Language': 0.0}\u001b[0m\n",
      "I am happy\n",
      "{'Anonymize': True, 'BanTopics': True, 'BanCompetitors': True, 'Toxicity': True, 'Code': True, 'Gibberish': True, 'Language': True}\n",
      "{'Anonymize': 0.0, 'BanTopics': 0.0, 'BanCompetitors': 0.0, 'Toxicity': 0.0, 'Code': 0.0, 'Gibberish': 0.0, 'Language': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from llm_guard import scan_prompt\n",
    "from llm_guard.input_scanners import (\n",
    "    Anonymize,\n",
    "    BanCompetitors,\n",
    "    BanTopics,\n",
    "    Code,\n",
    "    Gibberish,\n",
    "    Language,\n",
    "    PromptInjection,\n",
    "    Toxicity,\n",
    ")\n",
    "from llm_guard.input_scanners.anonymize_helpers import DEBERTA_AI4PRIVACY_v2_CONF\n",
    "from llm_guard.input_scanners.ban_competitors import MODEL_BASE as BAN_COMPETITORS_MODEL\n",
    "from llm_guard.input_scanners.ban_topics import MODEL_DEBERTA_BASE_V2 as BAN_TOPICS_MODEL\n",
    "from llm_guard.input_scanners.code import DEFAULT_MODEL as CODE_MODEL\n",
    "from llm_guard.input_scanners.gibberish import DEFAULT_MODEL as GIBBERISH_MODEL\n",
    "from llm_guard.input_scanners.language import DEFAULT_MODEL as LANGUAGE_MODEL\n",
    "from llm_guard.input_scanners.prompt_injection import V2_MODEL as PROMPT_INJECTION_MODEL\n",
    "from llm_guard.input_scanners.toxicity import DEFAULT_MODEL as TOXICITY_MODEL\n",
    "from llm_guard.vault import Vault\n",
    "\n",
    "PROMPT_INJECTION_MODEL.kwargs[\"local_files_only\"] = True\n",
    "PROMPT_INJECTION_MODEL.path = \"./deberta-v3-base-prompt-injection-v2\"\n",
    "\n",
    "DEBERTA_AI4PRIVACY_v2_CONF[\"DEFAULT_MODEL\"].path = \"./deberta-v3-base_finetuned_ai4privacy_v2\"\n",
    "DEBERTA_AI4PRIVACY_v2_CONF[\"DEFAULT_MODEL\"].kwargs[\"local_files_only\"] = True\n",
    "\n",
    "BAN_TOPICS_MODEL.path = \"./deberta-v3-base-zeroshot-v1.1-all-33\"\n",
    "BAN_TOPICS_MODEL.kwargs[\"local_files_only\"] = True\n",
    "\n",
    "TOXICITY_MODEL.path = \"./unbiased-toxic-roberta\"\n",
    "TOXICITY_MODEL.kwargs[\"local_files_only\"] = True\n",
    "\n",
    "BAN_COMPETITORS_MODEL.path = \"./span-marker-bert-base-orgs\"\n",
    "BAN_COMPETITORS_MODEL.kwargs[\"local_files_only\"] = True\n",
    "\n",
    "CODE_MODEL.path = \"./programming-language-identification\"\n",
    "CODE_MODEL.kwargs[\"local_files_only\"] = True\n",
    "\n",
    "GIBBERISH_MODEL.path = \"./autonlp-Gibberish-Detector-492513457\"\n",
    "GIBBERISH_MODEL.kwargs[\"local_files_only\"] = True\n",
    "\n",
    "LANGUAGE_MODEL.path = \"./xlm-roberta-base-language-detection\"\n",
    "LANGUAGE_MODEL.kwargs[\"local_files_only\"] = True\n",
    "\n",
    "vault = Vault()\n",
    "input_scanners = [\n",
    "    Anonymize(vault, recognizer_conf=DEBERTA_AI4PRIVACY_v2_CONF),\n",
    "    BanTopics([\"politics\", \"religion\"], model=BAN_TOPICS_MODEL),\n",
    "    BanCompetitors([\"google\", \"facebook\"], model=BAN_COMPETITORS_MODEL),\n",
    "    Toxicity(model=TOXICITY_MODEL),\n",
    "    Code([\"Python\", \"PHP\"], model=CODE_MODEL),\n",
    "    Gibberish(model=GIBBERISH_MODEL),\n",
    "    Language([\"en\"], model=LANGUAGE_MODEL),\n",
    "    PromptInjection(model=PROMPT_INJECTION_MODEL),\n",
    "]\n",
    "\n",
    "sanitized_prompt, results_valid, results_score = scan_prompt(\n",
    "    input_scanners,\n",
    "    \"I am happy\",\n",
    ")\n",
    "\n",
    "print(sanitized_prompt)\n",
    "print(results_valid)\n",
    "print(results_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
